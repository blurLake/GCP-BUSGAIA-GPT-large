{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7912b9a0",
   "metadata": {},
   "source": [
    "## Experiments with GPT-Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb4267e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.6.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.61.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.2.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38aea2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# NOTE\n",
    "# Comment out the following code if you are not running this notebook on NLULab (Azure).\n",
    "#\n",
    "\n",
    "#import os\n",
    "\n",
    "#cache_dir = '/home/jovyan/nlu2/.cache/transformers'\n",
    "#os.environ['TRANSFORMERS_CACHE'] = cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d511cde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1614378098133/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'no-gpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    gpu_stat = torch.cuda.device_count(), device\n",
    "else:\n",
    "    device = -1\n",
    "    gpu_stat = 'no-gpu'\n",
    "\n",
    "gpu_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8dd88f",
   "metadata": {},
   "source": [
    "### Model Size Chart\n",
    "\n",
    "|Size|Parameters|\n",
    "|--- | ---|\n",
    "|S|125M params|\n",
    "|M|1.3B params|\n",
    "|L|2.7B params|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac396ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"L\"  # Can be S, M, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84db3e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d42af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model (this might take a while)...\n",
      "CPU times: user 45.9 s, sys: 8.23 s, total: 54.2 s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def load_model(msize):\n",
    "    model_name = 'EleutherAI/gpt-neo-125M'\n",
    "    if msize == \"M\":\n",
    "        model_name = 'EleutherAI/gpt-neo-1.3B'\n",
    "    elif msize == \"L\":\n",
    "        model_name = 'EleutherAI/gpt-neo-2.7B'\n",
    "    return pipeline('text-generation', model=model_name, device=device)\n",
    "\n",
    "print(\"Loading model (this might take a while)...\")\n",
    "gpt_neo = load_model(model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb3f501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(prompt, temperature=0.9, do_sample=True, min_length=1, max_length=160, stop=[\"\\n\"], top_k=1):\n",
    "    prompt = prompt.rstrip()\n",
    "    _max_length = int(len(prompt.split())*1.5 + max_length)\n",
    "    choices = gpt_neo(\n",
    "        prompt, \n",
    "        temperature=temperature,\n",
    "        do_sample=do_sample,\n",
    "        min_length=min_length,\n",
    "        max_length=_max_length,\n",
    "        top_k=top_k\n",
    "    )\n",
    "    result = list()\n",
    "    for i in range(min(top_k, len(choices))):\n",
    "        output = choices[i].get('generated_text', '')\n",
    "        if output.startswith(prompt):\n",
    "            output = output[len(prompt):]\n",
    "        for s in stop:\n",
    "            _idx = output.find(s)\n",
    "            if _idx > -1:\n",
    "                output = output[:_idx]\n",
    "        result.append(output.strip())\n",
    "    if len(result) == 1:\n",
    "        result = result[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456fa7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "106f103c",
   "metadata": {},
   "source": [
    "#### Text Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1ebafd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 161 ms, total: 1min 27s\n",
      "Wall time: 21.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'worldâ€™s leading mobile telecommunications equipment and service provider. Ericsson is a global company with headquarters in Stockholm, Sweden, and operates in more than 200 countries and jurisdictions worldwide. With more than 5,600 employees, Ericsson is a leading global technology company. The Ericsson Group has approximately 30,000'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"As a company Ericsson is the\"\n",
    "complete(prompt, max_length=60, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2faba5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6d849f8",
   "metadata": {},
   "source": [
    "#### Question Answering (no context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b310a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 50s, sys: 978 ms, total: 4min 51s\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Up to 150 Mbps'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"\"\"\n",
    "Q: What is upload data-rate in LTE?\n",
    "A: 75 Mbps\n",
    "\n",
    "Q: What is EPS?\n",
    "A: Evolved Packet System\n",
    "\n",
    "Q: What is peak download rate for 4G?\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "complete(prompt, stop=[\"\\n\", \"Q:\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860a3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1460ad09",
   "metadata": {},
   "source": [
    "#### SQL Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28cfd168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 33s, sys: 808 ms, total: 5min 34s\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(*) FROM employees;'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"\"\"\n",
    "Q: List the names of employees at Ericsson?\n",
    "SQL: SELECT name FROM employees WHERE company = 'Ericsson';\n",
    "\n",
    "Q: Show the highest paid player at the NBA?\n",
    "SQL: SELECT * FROM players WHERE league = 'NBA' ORDER BY salary DESC LIMIT 1;\n",
    "\n",
    "Q: How many employees are there at GAIA?\n",
    "SQL: \n",
    "\"\"\"\n",
    "\n",
    "complete(prompt, stop=[\"\\n\", \"SQL:\"], temperature=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd670c",
   "metadata": {},
   "source": [
    "#### code generation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e36e475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "\n",
      "# Load the image\n",
      "img = tf.placeholder(tf.float32, shape=[None, 224, 224, 3])\n",
      "\n",
      "# Convert to numpy array\n",
      "img = tf.image.decode_jpeg(img, channels=3)\n",
      "\n",
      "# Convert to numpy array\n",
      "img = tf.image.convert_image_dtype(img, tf.float32)\n",
      "\n",
      "# Convert to numpy array\n",
      "img = tf.image.convert_image_dtype(img, tf.uint8)\n",
      "\n",
      "# Convert to numpy array\n",
      "img = tf.image.convert_image_dtype(img, tf.uint8)\n",
      "\n",
      "# Convert to numpy\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Generate python code for image classification\n",
    "\n",
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "\n",
    "#complete(prompt, stop=[])\n",
    "code = complete(prompt, stop=[])\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33e6c0",
   "metadata": {},
   "source": [
    "#### pandas code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5edf50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf8a42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( {\"Gender\": [\"boy\",\"boy\",\"boy\",\"boy\",\"boy\",\"girl\",\"girl\",\"girl\",\"girl\"],\n",
    "                   \"Division\": [\"one\",\"one\",\"one\",\"two\",\"two\",\"one\",\"one\",\"two\",\"two\"], \n",
    "                   \"Marks\": [50,55,67,85,44,84,65,56,87]} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f593f054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Division</th>\n",
       "      <th>Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boy</td>\n",
       "      <td>one</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy</td>\n",
       "      <td>one</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boy</td>\n",
       "      <td>one</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boy</td>\n",
       "      <td>two</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boy</td>\n",
       "      <td>two</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>girl</td>\n",
       "      <td>one</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>girl</td>\n",
       "      <td>one</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>girl</td>\n",
       "      <td>two</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>girl</td>\n",
       "      <td>two</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Division  Marks\n",
       "0    boy      one     50\n",
       "1    boy      one     55\n",
       "2    boy      one     67\n",
       "3    boy      two     85\n",
       "4    boy      two     44\n",
       "5   girl      one     84\n",
       "6   girl      one     65\n",
       "7   girl      two     56\n",
       "8   girl      two     87"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68c815a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "we have dataframe with fields \"Gender\", \"Division\" and \"Marks\".\n",
    "\n",
    "Q: 'How many unique values in Division Column?'\n",
    "A: 'df[\"Division\".nunique()]';\n",
    "\n",
    "Q: 'Find the Division of boy who scored 55 marks.'\n",
    "A: 'df.loc[(df.loc[:, \"Gender\"] == \"boy\") & (df.loc[:, \"Marks\"] == 55), \"Division\"]';\n",
    "\n",
    "Q: 'Find the average Marks scored by Girls.'\n",
    "A: 'np.mean(df.loc[(df.loc[:, \"Gender\"] == \"girl\"), \"Marks\"])'\n",
    "\n",
    "Q: 'Display Division of girl who scored maximum marks.'\n",
    "A: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "773948bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\'df.loc[(df.loc[:, \"Gender\"] == \"girl\") & (df.loc[:, \"Marks\"] == max(df.loc[:, \"Marks\"])), \"Division\"]\\''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete(prompt, stop=[\"\\n\", \"A:\"], temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb68d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    two\n",
       "Name: Division, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df.loc[:, \"Gender\"] == \"girl\") & (df.loc[:, \"Marks\"] == max(df.loc[:, \"Marks\"])), \"Division\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "761eafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "we have dataframe with fields \"Gender\", \"Division\" and \"Marks\".\n",
    "\n",
    "Q: 'How many unique values in Division Column?'\n",
    "A: 'df[\"Division\".nunique()]';\n",
    "\n",
    "Q: 'Find the Division of boy who scored 55 marks.'\n",
    "A: 'df.loc[(df.loc[:, \"Gender\"] == \"boy\") & (df.loc[:, \"Marks\"] == 55), \"Division\"]';\n",
    "\n",
    "Q: 'Find the average Marks scored by Girls.'\n",
    "A: 'np.mean(df.loc[(df.loc[:, \"Gender\"] == \"girl\"), \"Marks\"])'\n",
    "\n",
    "Q: 'Display Division of girl who scored maximum marks.'\n",
    "A: 'df.loc[(df.loc[:, \"Gender\"] == \"girl\") & (df.loc[:, \"Marks\"] == max(df.loc[:,\"Marks\"])), \"Division\"]'\n",
    "\n",
    "Q: 'Find the median Marks scored by Boys.'\n",
    "A: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6300f330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\'np.median(df.loc[(df.loc[:, \"Gender\"] == \"boy\"), \"Marks\"])\\''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete(prompt, stop=[\"\\n\", \"A:\"], temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d757b322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(df.loc[(df.loc[:, \"Gender\"] == \"boy\"), \"Marks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14700442",
   "metadata": {},
   "source": [
    "#### code generation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f51d7ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "def is_palindrome(s):\n",
    "    '''Check whether a string is a palindrome'''\n",
    "    return \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "069b0c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'all(s == s[::-1] for s in s)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete(prompt, stop=[\"\\n\"], temperature=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe60b219",
   "metadata": {},
   "source": [
    "#### summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6336e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "These latest enhancements to Ericssonâ€™s portfolio were developed in\n",
    "close collaboration with customers such as Verizon. They will enable\n",
    "service providers to seamlessly evolve towards cloud-native technologies\n",
    "and open network architectures and meet the demand for more deployment\n",
    "flexibility. Service providers will also be able to extend Ericsson\n",
    "Cloud RAN reach with seven million 5G-ready Ericsson Radio System radios\n",
    "already in the field globally.\n",
    "\\\"\\\"\\\"\n",
    "Summarize this paragraph:\n",
    "\\\"\\\"\\\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15856df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new Ericsson 5G-ready radio system is the worldâ€™s most\n",
      "advanced 5G-ready radio system\n"
     ]
    }
   ],
   "source": [
    "temp = complete(prompt, stop=[\"\\\"\\\"\\\"\", \".\"], max_length= 60, temperature=0.9, top_k = 3)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681661d3",
   "metadata": {},
   "source": [
    "#### Java script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38c29014",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Use list comprehension to convert this into one line of JavaScript:\\n\\ndogs.forEach((dog) => {\\n    car.push(dog);\\n});\\n\\nJavaScript one line version:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3148c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 258, but ``max_length`` is set to 202.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "temp = complete(prompt, stop=[\";\"], max_length= 100, temperature=0.01, top_k = 4)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67392c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How to define a name function in JavaScript?JavaScript example:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "619b3773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function name(name) {\n",
      "\n",
      "return name;\n"
     ]
    }
   ],
   "source": [
    "temp = complete(prompt, stop=[\"}\"], max_length= 100, temperature=0.5, top_k = 1)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a02eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How can you create an Array in JavaScript?JavaScript example:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1542ec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var myArray = []\n"
     ]
    }
   ],
   "source": [
    "temp = complete(prompt, stop=[\";\"], max_length= 100, temperature=0.5, top_k = 1)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518d373",
   "metadata": {},
   "source": [
    "#### k8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a12b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Generate Kubernetes Manifests from requirements.\n",
    "\n",
    "Q: 'Deploy the wordpress project with 2 replicas.'\n",
    "A: 'apiVersion: apps/v1\\n\\tkind: Deployment metadata: name: wordpress-deployment spec: replicas: 2'      \n",
    "\n",
    "Q: 'Deploy nginx with 3 replicas.'\n",
    "A: 'apiVersion: apps/v1  kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 3'\n",
    "\n",
    "Q: 'Deploy mongodb with two replicas.'\n",
    "A: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eab17b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'apiVersion: apps/v1  kind: Deployment metadata: name: mongodb-deployment spec: replicas: 2'\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete(prompt,max_length=100, temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af91f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Input: expose wordpress on port 80\n",
    "Output:\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: wordpress-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: wordpress\n",
    "  ports:\n",
    "    - protocol: TCP\n",
    "      port: 80\n",
    "\n",
    "Input: deploy wordpress with 2 replicas\n",
    "Output:\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: wordpress-deployment\n",
    "  labels:\n",
    "    app: wordpress\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: wordpress\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: wordpress\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: wordpress\n",
    "        image: wordpress:3.5.0\n",
    "        ports:\n",
    "        - containerPort: 80\n",
    "\n",
    "Input: deploy Elasticsearch\n",
    "Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21945bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: apps/v1\n",
      "kind: Deployment\n",
      "metadata:\n",
      "  name: elasticsearch-deployment\n",
      "  labels:\n",
      "    app: elasticsearch\n",
      "spec:\n",
      "  replicas: 3\n",
      "  selector:\n",
      "    matchLabels:\n",
      "      app: elasticsearch\n",
      "  template:\n",
      "    metadata:\n",
      "      labels:\n",
      "        app: elasticsearch\n",
      "    spec:\n",
      "      containers:\n",
      "      - name: elasticsearch\n",
      "        image: elasticsearch:2.4.5\n"
     ]
    }
   ],
   "source": [
    "temp = complete(prompt,stop = [\"\\n\\n\"], max_length=300, temperature=0.1)\n",
    "print(temp)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
